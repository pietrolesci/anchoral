{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from energizer.datastores import PandasDataStoreForSequenceClassification\n",
    "from src.strategies import FullSubset, RandomStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/pl487/.cache/huggingface/datasets/pietrolesci___parquet/pietrolesci--wiki_toxic_indexed-bbeb1b8d65bf4665/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e4556926454273bd371743ebd6e621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/pl487/.cache/huggingface/datasets/pietrolesci___parquet/pietrolesci--wiki_toxic_indexed-bbeb1b8d65bf4665/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-617ce17a7b47db48_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/pl487/.cache/huggingface/datasets/pietrolesci___parquet/pietrolesci--wiki_toxic_indexed-bbeb1b8d65bf4665/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ef736a700f5331c7_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/pl487/.cache/huggingface/datasets/pietrolesci___parquet/pietrolesci--wiki_toxic_indexed-bbeb1b8d65bf4665/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-302176ead9687723_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ds_dict = load_dataset(\"pietrolesci/wiki_toxic_indexed\").map(\n",
    "    lambda ex: tokenizer(ex[\"comment_text\"]), batched=True, num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PandasDataStoreForSequenceClassification()\n",
    "ds.from_dataset_dict(\n",
    "    ds_dict,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    target_name=\"labels\",\n",
    "    tokenizer=tokenizer,\n",
    "    uid_name=\"uid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_name = \"embedding_all-mpnet-base-v2\"\n",
    "ds.add_index(emb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=ds.id2label,\n",
    "    label2id=ds.label2id,\n",
    "    num_labels=len(ds.labels),\n",
    ")\n",
    "\n",
    "# estimator = RandomStrategy(model=model, accelerator=\"gpu\")\n",
    "estimator = FullSubset(\n",
    "    model=model,\n",
    "    accelerator=\"gpu\",\n",
    "    num_neighbours=100,\n",
    "    subset_size=10_000,\n",
    "    seed=42,\n",
    "    score_fn=\"least_confidence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.label(list(range(100)), -1)\n",
    "ds.prepare_for_loading(batch_size=32, eval_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abbf8c3056143f49c573f87284903cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed rounds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad81020e84843d799fa0ae80d9c7d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4632e485074c5facc9318aabb575a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45c9963f52c4266a33a3044e0197fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eb4ddfee06471d9e1f15dc5c186f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pool: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = estimator.active_fit(\n",
    "    ds,\n",
    "    query_size=50,\n",
    "    max_epochs=1,\n",
    "    limit_test_batches=2,\n",
    "    max_rounds=2,\n",
    "    limit_pool_batches=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 31915, 159571, 159571)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_dict[\"train\"]), len(ds_dict[\"validation\"]), len(ds.data), len(\n",
    "    ds_dict[\"train\"]\n",
    ") + len(ds_dict[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>uid</th>\n",
       "      <th>embedding_all-mpnet-base-v2</th>\n",
       "      <th>embedding_multi-qa-mpnet-base-dot-v1</th>\n",
       "      <th>embedding_all-MiniLM-L12-v2</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>is_labelled</th>\n",
       "      <th>is_validation</th>\n",
       "      <th>labelling_round</th>\n",
       "      <th>train_uid</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I very much looked forward to this movie. Its ...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>[-0.025794797, 0.050868154, -0.01413649, 0.004...</td>\n",
       "      <td>[-0.24517001, 0.15869692, -0.20793273, 0.20060...</td>\n",
       "      <td>[-0.08997142, -0.037334215, 0.012179131, -0.02...</td>\n",
       "      <td>[101, 1045, 2200, 2172, 2246, 2830, 2000, 2023...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>0.351936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are only two movies I would give a 1/10 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>[0.010214066, 0.035168514, 0.021841576, -0.034...</td>\n",
       "      <td>[-0.18534045, -0.15982038, -0.06648923, 0.0308...</td>\n",
       "      <td>[-0.042834364, -0.0033234707, -0.008627697, -0...</td>\n",
       "      <td>[101, 2045, 2024, 2069, 2048, 5691, 1045, 2052...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>0.299353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not only is it a disgustingly made low-budget ...</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>[0.029638596, 0.0747271, -0.020699004, 0.01253...</td>\n",
       "      <td>[-0.008488935, 0.034309033, -0.23201317, 0.074...</td>\n",
       "      <td>[-0.06461532, -0.049454708, -0.054552767, -0.0...</td>\n",
       "      <td>[101, 2025, 2069, 2003, 2009, 1037, 19424, 213...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>0.308445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In director Sooraj Barjatya's Vivah,20-somethi...</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.011529899, 0.07033135, -0.016396757, -0.016...</td>\n",
       "      <td>[-0.12023467, 0.27032727, -0.16782328, -0.0713...</td>\n",
       "      <td>[-0.0029073274, 0.037866402, 0.026605502, -0.0...</td>\n",
       "      <td>[101, 1999, 2472, 17111, 14220, 3347, 3900, 21...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>0.349822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maybe you shouldn't compare, but Wild Style an...</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>[-0.03354113, 0.034324, 0.0148819145, -0.00328...</td>\n",
       "      <td>[-0.3127217, 0.102947414, -0.047185007, 0.0484...</td>\n",
       "      <td>[-0.049723655, -0.0010385206, -0.0062440704, -...</td>\n",
       "      <td>[101, 2672, 2017, 5807, 1005, 1056, 12826, 101...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>8724.0</td>\n",
       "      <td>0.339425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>While the story is sweet, and the dancing and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>24017</td>\n",
       "      <td>[-0.03852864, 0.032753985, -0.032079127, 0.013...</td>\n",
       "      <td>[-0.16448122, -0.07015948, -0.25898105, 0.0735...</td>\n",
       "      <td>[-0.0526425, 0.012932369, 0.002774512, 0.00415...</td>\n",
       "      <td>[101, 2096, 1996, 2466, 2003, 4086, 1010, 1998...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>0.565121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>It was very heart-warming. As an expatriated f...</td>\n",
       "      <td>1</td>\n",
       "      <td>24291</td>\n",
       "      <td>[-0.027180221, 0.004869805, -0.0050957943, 0.0...</td>\n",
       "      <td>[-0.08668917, -0.28511098, -0.273917, 0.139006...</td>\n",
       "      <td>[-0.025526993, 0.040672258, -0.11157379, -0.16...</td>\n",
       "      <td>[101, 2009, 2001, 2200, 2540, 1011, 12959, 101...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.322476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Directed by Brian De Palma and written by Oliv...</td>\n",
       "      <td>1</td>\n",
       "      <td>24302</td>\n",
       "      <td>[-0.019601606, 0.04224149, -0.021460632, 0.044...</td>\n",
       "      <td>[-0.20593545, 0.1765558, -0.12829691, 0.399145...</td>\n",
       "      <td>[-0.05924157, -0.0105029335, -0.08769067, -0.0...</td>\n",
       "      <td>[101, 2856, 2011, 4422, 2139, 23985, 1998, 251...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>0.495365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>this was a very good movie i wished i could fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>24538</td>\n",
       "      <td>[0.009553274, 0.031344377, 0.0038972297, -0.02...</td>\n",
       "      <td>[-0.12809247, -0.12758648, -0.33170307, -0.071...</td>\n",
       "      <td>[-0.08255486, -0.04266798, -0.049890228, -0.04...</td>\n",
       "      <td>[101, 2023, 2001, 1037, 2200, 2204, 3185, 1045...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.433209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Contrary to some people's summaries, the women...</td>\n",
       "      <td>1</td>\n",
       "      <td>24847</td>\n",
       "      <td>[0.032291785, 0.015265296, 0.009854892, 0.0394...</td>\n",
       "      <td>[0.13558666, -0.022968156, -0.15880717, 0.4468...</td>\n",
       "      <td>[-0.026806647, 0.013943328, -0.010418449, 0.02...</td>\n",
       "      <td>[101, 10043, 2000, 2070, 2111, 1005, 1055, 768...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.348650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels    uid   \n",
       "0    I very much looked forward to this movie. Its ...       0     39  \\\n",
       "1    There are only two movies I would give a 1/10 ...       0     72   \n",
       "2    Not only is it a disgustingly made low-budget ...       0     93   \n",
       "3    In director Sooraj Barjatya's Vivah,20-somethi...       0    142   \n",
       "4    Maybe you shouldn't compare, but Wild Style an...       0    173   \n",
       "..                                                 ...     ...    ...   \n",
       "595  While the story is sweet, and the dancing and ...       1  24017   \n",
       "596  It was very heart-warming. As an expatriated f...       1  24291   \n",
       "597  Directed by Brian De Palma and written by Oliv...       1  24302   \n",
       "598  this was a very good movie i wished i could fi...       1  24538   \n",
       "599  Contrary to some people's summaries, the women...       1  24847   \n",
       "\n",
       "                           embedding_all-mpnet-base-v2   \n",
       "0    [-0.025794797, 0.050868154, -0.01413649, 0.004...  \\\n",
       "1    [0.010214066, 0.035168514, 0.021841576, -0.034...   \n",
       "2    [0.029638596, 0.0747271, -0.020699004, 0.01253...   \n",
       "3    [0.011529899, 0.07033135, -0.016396757, -0.016...   \n",
       "4    [-0.03354113, 0.034324, 0.0148819145, -0.00328...   \n",
       "..                                                 ...   \n",
       "595  [-0.03852864, 0.032753985, -0.032079127, 0.013...   \n",
       "596  [-0.027180221, 0.004869805, -0.0050957943, 0.0...   \n",
       "597  [-0.019601606, 0.04224149, -0.021460632, 0.044...   \n",
       "598  [0.009553274, 0.031344377, 0.0038972297, -0.02...   \n",
       "599  [0.032291785, 0.015265296, 0.009854892, 0.0394...   \n",
       "\n",
       "                  embedding_multi-qa-mpnet-base-dot-v1   \n",
       "0    [-0.24517001, 0.15869692, -0.20793273, 0.20060...  \\\n",
       "1    [-0.18534045, -0.15982038, -0.06648923, 0.0308...   \n",
       "2    [-0.008488935, 0.034309033, -0.23201317, 0.074...   \n",
       "3    [-0.12023467, 0.27032727, -0.16782328, -0.0713...   \n",
       "4    [-0.3127217, 0.102947414, -0.047185007, 0.0484...   \n",
       "..                                                 ...   \n",
       "595  [-0.16448122, -0.07015948, -0.25898105, 0.0735...   \n",
       "596  [-0.08668917, -0.28511098, -0.273917, 0.139006...   \n",
       "597  [-0.20593545, 0.1765558, -0.12829691, 0.399145...   \n",
       "598  [-0.12809247, -0.12758648, -0.33170307, -0.071...   \n",
       "599  [0.13558666, -0.022968156, -0.15880717, 0.4468...   \n",
       "\n",
       "                           embedding_all-MiniLM-L12-v2   \n",
       "0    [-0.08997142, -0.037334215, 0.012179131, -0.02...  \\\n",
       "1    [-0.042834364, -0.0033234707, -0.008627697, -0...   \n",
       "2    [-0.06461532, -0.049454708, -0.054552767, -0.0...   \n",
       "3    [-0.0029073274, 0.037866402, 0.026605502, -0.0...   \n",
       "4    [-0.049723655, -0.0010385206, -0.0062440704, -...   \n",
       "..                                                 ...   \n",
       "595  [-0.0526425, 0.012932369, 0.002774512, 0.00415...   \n",
       "596  [-0.025526993, 0.040672258, -0.11157379, -0.16...   \n",
       "597  [-0.05924157, -0.0105029335, -0.08769067, -0.0...   \n",
       "598  [-0.08255486, -0.04266798, -0.049890228, -0.04...   \n",
       "599  [-0.026806647, 0.013943328, -0.010418449, 0.02...   \n",
       "\n",
       "                                             input_ids   \n",
       "0    [101, 1045, 2200, 2172, 2246, 2830, 2000, 2023...  \\\n",
       "1    [101, 2045, 2024, 2069, 2048, 5691, 1045, 2052...   \n",
       "2    [101, 2025, 2069, 2003, 2009, 1037, 19424, 213...   \n",
       "3    [101, 1999, 2472, 17111, 14220, 3347, 3900, 21...   \n",
       "4    [101, 2672, 2017, 5807, 1005, 1056, 12826, 101...   \n",
       "..                                                 ...   \n",
       "595  [101, 2096, 1996, 2466, 2003, 4086, 1010, 1998...   \n",
       "596  [101, 2009, 2001, 2200, 2540, 1011, 12959, 101...   \n",
       "597  [101, 2856, 2011, 4422, 2139, 23985, 1998, 251...   \n",
       "598  [101, 2023, 2001, 1037, 2200, 2204, 3185, 1045...   \n",
       "599  [101, 10043, 2000, 2070, 2111, 1005, 1055, 768...   \n",
       "\n",
       "                                        token_type_ids   \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \\\n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "595  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "596  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        attention_mask  is_labelled   \n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True  \\\n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "..                                                 ...          ...   \n",
       "595  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "596  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "597  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "598  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "599  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "\n",
       "     is_validation  labelling_round  train_uid     dists  \n",
       "0            False                8     5066.0  0.351936  \n",
       "1            False                6     1207.0  0.299353  \n",
       "2            False                3     2655.0  0.308445  \n",
       "3            False                8     2194.0  0.349822  \n",
       "4            False               10     8724.0  0.339425  \n",
       "..             ...              ...        ...       ...  \n",
       "595          False                9     4635.0  0.565121  \n",
       "596          False               10     1270.0  0.322476  \n",
       "597          False                6     2116.0  0.495365  \n",
       "598          False                1      993.0  0.433209  \n",
       "599          False               10     1270.0  0.348650  \n",
       "\n",
       "[600 rows x 14 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\n",
    "    \"/home/pl487/allset/outputs/debug/imdb/randomguide_2023-05-19T16-28-44/logs/labelled_dataset.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>train_uid</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_train</th>\n",
       "      <th>uid_train</th>\n",
       "      <th>comment_text_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1778</td>\n",
       "      <td>17430</td>\n",
       "      <td>FUCK YOU, GO SUCK SOME DOG COCK! YOU FUCKING D...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17430</td>\n",
       "      <td>faggot faggot faggot faggot faggot faggot fagg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153620</td>\n",
       "      <td>17430</td>\n",
       "      <td>your retarded your retardedyour retardedyour r...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17430</td>\n",
       "      <td>faggot faggot faggot faggot faggot faggot fagg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3473</td>\n",
       "      <td>12</td>\n",
       "      <td>mother fucker  \\n\\nfuck off dick face</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>FUCK FUCKITY FUCK FUCK FUCK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18971</td>\n",
       "      <td>12</td>\n",
       "      <td>FUCK YOU FUCK YOU FUCK YOUa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>FUCK FUCKITY FUCK FUCK FUCK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22022</td>\n",
       "      <td>12</td>\n",
       "      <td>fuck you bitch nigger slut ass fuck whore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>FUCK FUCKITY FUCK FUCK FUCK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>133062</td>\n",
       "      <td>3473</td>\n",
       "      <td>In Response - FUCK YOU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3473</td>\n",
       "      <td>mother fucker  \\n\\nfuck off dick face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>137282</td>\n",
       "      <td>98</td>\n",
       "      <td>FUCK OF NAZI PROPAGANDA\\nodpierdalcie sie jeba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>Pilecki's organisation1940-43 \\n\\nYears before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>140537</td>\n",
       "      <td>68120</td>\n",
       "      <td>what's up asshole bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68120</td>\n",
       "      <td>Fuck Off \\n\\nFuck Off i do what i want bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>146906</td>\n",
       "      <td>47126</td>\n",
       "      <td>Stop talking to me \\n\\nShut the fuck up you st...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47126</td>\n",
       "      <td>hay fuck youhay fuck you \\n\\nhay fuck you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>153581</td>\n",
       "      <td>111030</td>\n",
       "      <td>I was speaking the truth u son of a bitch go f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111030</td>\n",
       "      <td>Fuck Off! \\n\\nFuck Off!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid train_uid                                       comment_text   \n",
       "0     1778     17430  FUCK YOU, GO SUCK SOME DOG COCK! YOU FUCKING D...  \\\n",
       "1   153620     17430  your retarded your retardedyour retardedyour r...   \n",
       "2     3473        12              mother fucker  \\n\\nfuck off dick face   \n",
       "3    18971        12                        FUCK YOU FUCK YOU FUCK YOUa   \n",
       "4    22022        12          fuck you bitch nigger slut ass fuck whore   \n",
       "..     ...       ...                                                ...   \n",
       "95  133062      3473                             In Response - FUCK YOU   \n",
       "96  137282        98  FUCK OF NAZI PROPAGANDA\\nodpierdalcie sie jeba...   \n",
       "97  140537     68120                            what's up asshole bitch   \n",
       "98  146906     47126  Stop talking to me \\n\\nShut the fuck up you st...   \n",
       "99  153581    111030  I was speaking the truth u son of a bitch go f...   \n",
       "\n",
       "    labels  labels_train uid_train   \n",
       "0        1             1     17430  \\\n",
       "1        1             1     17430   \n",
       "2        1             1        12   \n",
       "3        1             1        12   \n",
       "4        1             1        12   \n",
       "..     ...           ...       ...   \n",
       "95       1             1      3473   \n",
       "96       1             0        98   \n",
       "97       1             1     68120   \n",
       "98       1             1     47126   \n",
       "99       1             1    111030   \n",
       "\n",
       "                                   comment_text_train  \n",
       "0   faggot faggot faggot faggot faggot faggot fagg...  \n",
       "1   faggot faggot faggot faggot faggot faggot fagg...  \n",
       "2                         FUCK FUCKITY FUCK FUCK FUCK  \n",
       "3                         FUCK FUCKITY FUCK FUCK FUCK  \n",
       "4                         FUCK FUCKITY FUCK FUCK FUCK  \n",
       "..                                                ...  \n",
       "95              mother fucker  \\n\\nfuck off dick face  \n",
       "96  Pilecki's organisation1940-43 \\n\\nYears before...  \n",
       "97       Fuck Off \\n\\nFuck Off i do what i want bitch  \n",
       "98          hay fuck youhay fuck you \\n\\nhay fuck you  \n",
       "99                            Fuck Off! \\n\\nFuck Off!  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(\n",
    "    df.loc[df[\"train_uid\"].notna(), [\"uid\", \"train_uid\", \"comment_text\", \"labels\"]],\n",
    "    df[[\"labels\", \"uid\", \"comment_text\"]],\n",
    "    left_on=\"train_uid\",\n",
    "    right_on=\"uid\",\n",
    "    how=\"inner\",\n",
    "    suffixes=[\"\", \"_train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid\n",
       "0         1\n",
       "106377    1\n",
       "106378    1\n",
       "106379    1\n",
       "106380    1\n",
       "         ..\n",
       "53191     1\n",
       "53192     1\n",
       "53193     1\n",
       "53186     1\n",
       "159570    1\n",
       "Length: 159571, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.groupby(\"uid\").size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelling_round\n",
       "-1    100\n",
       " 1     50\n",
       " 2     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.data\n",
    "\n",
    "df.loc[df[\"is_labelled\"] == True].groupby(\"labelling_round\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[\"uid\"].nunique() == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df[\"train_uid\"][df[\"train_uid\"].notna()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uid\"].isin(df[\"train_uid\"]).sum() / df[\"train_uid\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"train_uid\"].notna(), \"train_uid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1    93\n",
       "0     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"train_uid\"].notna(), \"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>uid</th>\n",
       "      <th>embedding_all-mpnet-base-v2</th>\n",
       "      <th>embedding_multi-qa-mpnet-base-dot-v1</th>\n",
       "      <th>embedding_all-MiniLM-L12-v2</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>is_labelled</th>\n",
       "      <th>is_validation</th>\n",
       "      <th>labelling_round</th>\n",
       "      <th>train_uid</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1644bccf6f37f19e</td>\n",
       "      <td>FUCK YOU, GO SUCK SOME DOG COCK! YOU FUCKING D...</td>\n",
       "      <td>1</td>\n",
       "      <td>1778</td>\n",
       "      <td>[0.01764762, 0.05288508, -0.010527764, -0.0131...</td>\n",
       "      <td>[-0.045378618, -0.25800213, -0.44898406, -0.27...</td>\n",
       "      <td>[-0.041358825, 0.015455857, 0.0055711074, -0.0...</td>\n",
       "      <td>[101, 6616, 2017, 1010, 2175, 11891, 2070, 389...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>17430</td>\n",
       "      <td>0.538952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>6aa03f857ba747da</td>\n",
       "      <td>mother fucker  \\n\\nfuck off dick face</td>\n",
       "      <td>1</td>\n",
       "      <td>3473</td>\n",
       "      <td>[-0.021624373, 0.03843027, -0.007751778, 0.059...</td>\n",
       "      <td>[-0.16709238, -0.5578038, -0.39088944, -0.1443...</td>\n",
       "      <td>[-0.060571082, 0.044763703, 0.0028691227, 0.00...</td>\n",
       "      <td>[101, 2388, 6616, 2121, 6616, 2125, 5980, 2227...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.573351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>d6ab1b62b0d08a2e</td>\n",
       "      <td>why don't you suck my ass until your lips blee...</td>\n",
       "      <td>1</td>\n",
       "      <td>7928</td>\n",
       "      <td>[-0.009330071, 0.098941974, 0.013997296, 0.010...</td>\n",
       "      <td>[-0.023266658, -0.18005346, -0.28239602, -0.11...</td>\n",
       "      <td>[-0.055138674, -0.016808288, 0.017413128, -0.0...</td>\n",
       "      <td>[101, 2339, 2123, 1005, 1056, 2017, 11891, 202...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.500528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10187</th>\n",
       "      <td>18f8afbb8f66304c</td>\n",
       "      <td>YOU ARE A F**KING LIAR!</td>\n",
       "      <td>1</td>\n",
       "      <td>10187</td>\n",
       "      <td>[0.014268233, 0.050565224, -0.020841537, 0.091...</td>\n",
       "      <td>[-0.095857754, -0.22293137, -0.4484912, 0.0633...</td>\n",
       "      <td>[-0.06453303, 0.025427138, 0.008142441, -0.010...</td>\n",
       "      <td>[101, 2017, 2024, 1037, 1042, 1008, 1008, 2332...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0.600376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648</th>\n",
       "      <td>b9875864a7d2a30c</td>\n",
       "      <td>Alrighty\\n\\nYou can go fuck yourself.</td>\n",
       "      <td>1</td>\n",
       "      <td>10648</td>\n",
       "      <td>[-0.026609253, 0.09604505, -0.003319245, -0.02...</td>\n",
       "      <td>[-0.16098726, -0.103996314, -0.40565914, -0.17...</td>\n",
       "      <td>[0.035441663, -0.083025225, 0.012442009, 0.002...</td>\n",
       "      <td>[101, 10303, 2100, 2017, 2064, 2175, 6616, 442...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>18971</td>\n",
       "      <td>0.302180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153581</th>\n",
       "      <td>0468dd91f5506285</td>\n",
       "      <td>I was speaking the truth u son of a bitch go f...</td>\n",
       "      <td>1</td>\n",
       "      <td>153581</td>\n",
       "      <td>[0.0038699205, 0.03174462, 0.0025089267, 0.002...</td>\n",
       "      <td>[0.08494834, -0.21561271, -0.34298617, -0.2999...</td>\n",
       "      <td>[-0.031451266, -0.020049753, 0.017962962, -0.0...</td>\n",
       "      <td>[101, 1045, 2001, 4092, 1996, 3606, 1057, 2365...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>111030</td>\n",
       "      <td>0.473465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153620</th>\n",
       "      <td>e1469c196b2c8724</td>\n",
       "      <td>your retarded your retardedyour retardedyour r...</td>\n",
       "      <td>1</td>\n",
       "      <td>153620</td>\n",
       "      <td>[0.050225183, 0.022684412, 0.019161776, -0.020...</td>\n",
       "      <td>[-0.08857655, -0.41304967, -0.32461682, -0.113...</td>\n",
       "      <td>[0.015227961, -0.05367273, 0.08996908, 0.03628...</td>\n",
       "      <td>[101, 2115, 2128, 7559, 5732, 2115, 2128, 7559...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>17430</td>\n",
       "      <td>0.501090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155097</th>\n",
       "      <td>7e40d2ad4ef45b62</td>\n",
       "      <td>FUCK YOU! FUCK YOU! FUCK YOU! FUCK YOU! \\nFUCK...</td>\n",
       "      <td>1</td>\n",
       "      <td>155097</td>\n",
       "      <td>[-0.033801775, 0.037717223, -0.010647806, -0.0...</td>\n",
       "      <td>[-0.19134074, -0.17650607, -0.44849518, -0.236...</td>\n",
       "      <td>[-0.0728808, 0.111763485, -0.03898648, -0.0915...</td>\n",
       "      <td>[101, 6616, 2017, 999, 6616, 2017, 999, 6616, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.490013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159013</th>\n",
       "      <td>365a53aa15419ac2</td>\n",
       "      <td>Fuck you Motha Fucka \\n\\nPenis</td>\n",
       "      <td>1</td>\n",
       "      <td>159013</td>\n",
       "      <td>[-0.0014293266, -0.03462546, -0.014728903, 0.0...</td>\n",
       "      <td>[-0.14177944, -0.6943717, -0.44628122, -0.1260...</td>\n",
       "      <td>[-0.09731447, 0.11882899, -0.05196268, -0.0270...</td>\n",
       "      <td>[101, 6616, 2017, 5820, 2050, 6616, 2050, 1908...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.480344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159052</th>\n",
       "      <td>b9209e3bdd7c61ec</td>\n",
       "      <td>fuck u jimmy wales fuck fuck fuck</td>\n",
       "      <td>1</td>\n",
       "      <td>159052</td>\n",
       "      <td>[-0.057233837, -0.0066889925, -0.0006736969, -...</td>\n",
       "      <td>[-0.43252534, -0.17550896, -0.3891853, -0.1529...</td>\n",
       "      <td>[-0.007114937, 0.03834407, -0.029214768, -0.08...</td>\n",
       "      <td>[101, 6616, 1057, 5261, 3575, 6616, 6616, 6616...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.528181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text   \n",
       "1778    1644bccf6f37f19e  FUCK YOU, GO SUCK SOME DOG COCK! YOU FUCKING D...  \\\n",
       "3473    6aa03f857ba747da              mother fucker  \\n\\nfuck off dick face   \n",
       "7928    d6ab1b62b0d08a2e  why don't you suck my ass until your lips blee...   \n",
       "10187   18f8afbb8f66304c                            YOU ARE A F**KING LIAR!   \n",
       "10648   b9875864a7d2a30c              Alrighty\\n\\nYou can go fuck yourself.   \n",
       "...                  ...                                                ...   \n",
       "153581  0468dd91f5506285  I was speaking the truth u son of a bitch go f...   \n",
       "153620  e1469c196b2c8724  your retarded your retardedyour retardedyour r...   \n",
       "155097  7e40d2ad4ef45b62  FUCK YOU! FUCK YOU! FUCK YOU! FUCK YOU! \\nFUCK...   \n",
       "159013  365a53aa15419ac2                     Fuck you Motha Fucka \\n\\nPenis   \n",
       "159052  b9209e3bdd7c61ec                  fuck u jimmy wales fuck fuck fuck   \n",
       "\n",
       "        labels     uid                        embedding_all-mpnet-base-v2   \n",
       "1778         1    1778  [0.01764762, 0.05288508, -0.010527764, -0.0131...  \\\n",
       "3473         1    3473  [-0.021624373, 0.03843027, -0.007751778, 0.059...   \n",
       "7928         1    7928  [-0.009330071, 0.098941974, 0.013997296, 0.010...   \n",
       "10187        1   10187  [0.014268233, 0.050565224, -0.020841537, 0.091...   \n",
       "10648        1   10648  [-0.026609253, 0.09604505, -0.003319245, -0.02...   \n",
       "...        ...     ...                                                ...   \n",
       "153581       1  153581  [0.0038699205, 0.03174462, 0.0025089267, 0.002...   \n",
       "153620       1  153620  [0.050225183, 0.022684412, 0.019161776, -0.020...   \n",
       "155097       1  155097  [-0.033801775, 0.037717223, -0.010647806, -0.0...   \n",
       "159013       1  159013  [-0.0014293266, -0.03462546, -0.014728903, 0.0...   \n",
       "159052       1  159052  [-0.057233837, -0.0066889925, -0.0006736969, -...   \n",
       "\n",
       "                     embedding_multi-qa-mpnet-base-dot-v1   \n",
       "1778    [-0.045378618, -0.25800213, -0.44898406, -0.27...  \\\n",
       "3473    [-0.16709238, -0.5578038, -0.39088944, -0.1443...   \n",
       "7928    [-0.023266658, -0.18005346, -0.28239602, -0.11...   \n",
       "10187   [-0.095857754, -0.22293137, -0.4484912, 0.0633...   \n",
       "10648   [-0.16098726, -0.103996314, -0.40565914, -0.17...   \n",
       "...                                                   ...   \n",
       "153581  [0.08494834, -0.21561271, -0.34298617, -0.2999...   \n",
       "153620  [-0.08857655, -0.41304967, -0.32461682, -0.113...   \n",
       "155097  [-0.19134074, -0.17650607, -0.44849518, -0.236...   \n",
       "159013  [-0.14177944, -0.6943717, -0.44628122, -0.1260...   \n",
       "159052  [-0.43252534, -0.17550896, -0.3891853, -0.1529...   \n",
       "\n",
       "                              embedding_all-MiniLM-L12-v2   \n",
       "1778    [-0.041358825, 0.015455857, 0.0055711074, -0.0...  \\\n",
       "3473    [-0.060571082, 0.044763703, 0.0028691227, 0.00...   \n",
       "7928    [-0.055138674, -0.016808288, 0.017413128, -0.0...   \n",
       "10187   [-0.06453303, 0.025427138, 0.008142441, -0.010...   \n",
       "10648   [0.035441663, -0.083025225, 0.012442009, 0.002...   \n",
       "...                                                   ...   \n",
       "153581  [-0.031451266, -0.020049753, 0.017962962, -0.0...   \n",
       "153620  [0.015227961, -0.05367273, 0.08996908, 0.03628...   \n",
       "155097  [-0.0728808, 0.111763485, -0.03898648, -0.0915...   \n",
       "159013  [-0.09731447, 0.11882899, -0.05196268, -0.0270...   \n",
       "159052  [-0.007114937, 0.03834407, -0.029214768, -0.08...   \n",
       "\n",
       "                                                input_ids   \n",
       "1778    [101, 6616, 2017, 1010, 2175, 11891, 2070, 389...  \\\n",
       "3473    [101, 2388, 6616, 2121, 6616, 2125, 5980, 2227...   \n",
       "7928    [101, 2339, 2123, 1005, 1056, 2017, 11891, 202...   \n",
       "10187   [101, 2017, 2024, 1037, 1042, 1008, 1008, 2332...   \n",
       "10648   [101, 10303, 2100, 2017, 2064, 2175, 6616, 442...   \n",
       "...                                                   ...   \n",
       "153581  [101, 1045, 2001, 4092, 1996, 3606, 1057, 2365...   \n",
       "153620  [101, 2115, 2128, 7559, 5732, 2115, 2128, 7559...   \n",
       "155097  [101, 6616, 2017, 999, 6616, 2017, 999, 6616, ...   \n",
       "159013  [101, 6616, 2017, 5820, 2050, 6616, 2050, 1908...   \n",
       "159052  [101, 6616, 1057, 5261, 3575, 6616, 6616, 6616...   \n",
       "\n",
       "                                           token_type_ids   \n",
       "1778    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \\\n",
       "3473                          [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "7928    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10187                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10648                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                                                   ...   \n",
       "153581  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "153620  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "155097  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "159013                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "159052                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                           attention_mask  is_labelled   \n",
       "1778    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True  \\\n",
       "3473                          [1, 1, 1, 1, 1, 1, 1, 1, 1]         True   \n",
       "7928    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "10187                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]         True   \n",
       "10648                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]         True   \n",
       "...                                                   ...          ...   \n",
       "153581  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "153620  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "155097  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         True   \n",
       "159013                        [1, 1, 1, 1, 1, 1, 1, 1, 1]         True   \n",
       "159052                        [1, 1, 1, 1, 1, 1, 1, 1, 1]         True   \n",
       "\n",
       "        is_validation  labelling_round train_uid     dists  \n",
       "1778            False                2     17430  0.538952  \n",
       "3473            False                1        12  0.573351  \n",
       "7928            False                1        24  0.500528  \n",
       "10187           False                2        59  0.600376  \n",
       "10648           False                2     18971  0.302180  \n",
       "...               ...              ...       ...       ...  \n",
       "153581          False                2    111030  0.473465  \n",
       "153620          False                2     17430  0.501090  \n",
       "155097          False                1        12  0.490013  \n",
       "159013          False                1        12  0.480344  \n",
       "159052          False                1        12  0.528181  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.loc[~ds.data[\"train_uid\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = estimator.fit(train_loader=ds.test_loader(), max_epochs=1, limit_train_batches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.current_pool[\"train_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = ds.get_embeddings([96, 156443]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ClassificationActiveDataModule.from_dataset_dict(\n",
    "    dataset_dict, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.load_index(meta[\"hnsw_index_path\"], embedding_dim=meta[\"embedding_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    meta[\"name_or_path\"],\n",
    "    id2label=datamodule.id2label,\n",
    "    label2id=datamodule.label2id,\n",
    "    num_labels=len(datamodule.labels),\n",
    ")\n",
    "active_estimator = SimilaritySearchStrategyForSequenceClassification(\n",
    "    model=model, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_estimator.active_fit(\n",
    "    max_rounds=2,\n",
    "    query_size=100,\n",
    "    active_datamodule=datamodule,\n",
    "    limit_test_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_estimator.progress_tracker.budget_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = datamodule.train_loader()\n",
    "batch = next(iter(loader))\n",
    "_ = batch.pop(\"on_cpu\")\n",
    "batch_size = loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = torch.autograd.grad(loss, list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(model, input_ids, attn_mask, target):\n",
    "    input_ids = input_ids.unsqueeze(0)  # prepend batch dimension for processing\n",
    "    attn_mask = attn_mask.unsqueeze(0)  # prepend batch dimension for processing\n",
    "    target = target.unsqueeze(0)\n",
    "    loss = model(input_ids=input_ids, attention_mask=attn_mask, labels=target).loss\n",
    "    return torch.autograd.grad(loss, list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, target = (\n",
    "    batch[\"input_ids\"],\n",
    "    batch[\"attention_mask\"],\n",
    "    batch[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(i):\n",
    "    return input_ids[i], attention_mask[i], target[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.array(\n",
    "    [\n",
    "        [g.norm(2).item() for g in compute_grad(model, *select(i))]\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import grad, make_functional_with_buffers, vmap\n",
    "\n",
    "fmodel, params, buffers = make_functional_with_buffers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_stateless_model(\n",
    "    fmodel, params, buffers, input_ids, att_mask, label\n",
    "):\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    att_mask = att_mask.unsqueeze(0)\n",
    "    label = label.unsqueeze(0)\n",
    "\n",
    "    return fmodel(\n",
    "        params,\n",
    "        buffers,\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=att_mask,\n",
    "        labels=label,\n",
    "    ).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss_stateless_model(fmodel, params, buffers, *select(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_compute_grad = grad(compute_loss_stateless_model, argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_compute_grad(fmodel, params, buffers, *select(0))[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fnorms = np.array(\n",
    "    [\n",
    "        [\n",
    "            g.norm(2).item()\n",
    "            for g in ft_compute_grad(fmodel, params, buffers, *select(i))\n",
    "        ]\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(fmodel, params, buffers, input_ids, attention_mask, target):\n",
    "    grads = ft_compute_grad(\n",
    "        fmodel, params, buffers, input_ids, attention_mask, target\n",
    "    )\n",
    "    return tuple(g.norm() for g in grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_compute_sample_grad = vmap(\n",
    "    compute_norm, in_dims=(None, None, None, 0, 0, 0), randomness=\"same\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnorms_vmap = torch.stack(\n",
    "    ft_compute_sample_grad(\n",
    "        fmodel, params, buffers, input_ids, attention_mask, target\n",
    "    )\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnorms_vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can double check that the results using functorch grad and vmap match the results of hand processing each one individually:\n",
    "for per_sample_grad, ft_per_sample_grad in zip(\n",
    "    per_sample_grads, ft_per_sample_grads\n",
    "):\n",
    "    assert torch.allclose(per_sample_grad, ft_per_sample_grad, atol=3e-3, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_per_sample_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import srsly\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from src.data.active_datamodule import ActiveClassificationDataModule\n",
    "from src.data.datamodule import ClassificationDataModule\n",
    "from src.enums import SpecialKeys\n",
    "from src.estimator import Estimator\n",
    "from src.huggingface import (\n",
    "    EstimatorForSequenceClassification,\n",
    "    UncertaintyBasedStrategyForSequenceClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/prepared/ag_news\")\n",
    "dataset_dict = load_from_disk(data_path)\n",
    "metadata = srsly.read_yaml(data_path / \"metadata.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(metadata[\"name_or_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ClassificationDataModule.from_dataset_dict(\n",
    "    dataset_dict, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    metadata[\"name_or_path\"],\n",
    "    num_labels=len(datamodule.labels),\n",
    "    id2label=datamodule.id2label,\n",
    "    label2id=datamodule.label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = EstimatorForSequenceClassification(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = estimator.fit(\n",
    "    train_loader=datamodule.train_loader(),\n",
    "    validation_loader=datamodule.validation_loader(),\n",
    "    limit_train_batches=10,\n",
    "    limit_validation_batches=10,\n",
    "    max_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_estimator = UncertaintyBasedStrategyForSequenceClassification(\n",
    "    model, score_fn=\"margin_confidence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = active_estimator.fit(\n",
    "    train_loader=datamodule.train_loader(),\n",
    "    validation_loader=datamodule.validation_loader(),\n",
    "    limit_train_batches=10,\n",
    "    limit_validation_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_datamodule = ActiveClassificationDataModule.from_dataset_dict(\n",
    "    dataset_dict,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_out = active_estimator.active_fit(\n",
    "    active_datamodule=active_datamodule,\n",
    "    max_rounds=3,\n",
    "    query_size=50,\n",
    "    validation_perc=0.3,\n",
    "    fit_kwargs={\n",
    "        \"max_epochs\": 3,\n",
    "        \"limit_train_batches\": 3,\n",
    "        \"limit_validation_batches\": 3,\n",
    "    },\n",
    "    test_kwargs={\"limit_batches\": 3},\n",
    "    pool_kwargs={\"limit_batches\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_datamodule.save_labelled_dataset(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"results/labelled_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e53e394f14fe34c9aaf890e1aef4b8dd57ac2a780afaa542e758e0a4ed635da0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
