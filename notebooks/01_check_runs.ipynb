{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import srsly\n",
    "from tbparse import SummaryReader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../outputs/main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_hparams = []\n",
    "unfinished = []\n",
    "hparams = []\n",
    "\n",
    "DATASETS = set()\n",
    "DATA_SEEDS = set()\n",
    "MODEL_SEEDS = set()\n",
    "INIT_SEEDS = set()\n",
    "STRATEGIES = set()\n",
    "\n",
    "for dataset in path.iterdir():\n",
    "    # ignore .submitit folder and the multirun.yaml file\n",
    "    if \".submitit\" in str(dataset) or not dataset.is_dir():\n",
    "        continue\n",
    "\n",
    "    DATASETS.add(dataset.name)\n",
    "    for experiment in dataset.iterdir():\n",
    "        # check experiment metadata\n",
    "        hparams_file = experiment / \"hparams.yaml\"\n",
    "        if not hparams_file.exists():\n",
    "            missing_hparams.append(experiment)\n",
    "        else:\n",
    "            meta = srsly.read_yaml(hparams_file)\n",
    "            exp_hparam = {\n",
    "                \"experiment\": experiment,\n",
    "                \"data_seed\": meta[\"data\"][\"seed\"],\n",
    "                \"model_seed\": meta[\"model\"][\"seed\"],\n",
    "                \"initial_seed\": meta[\"active_data\"][\"seed\"],\n",
    "                \"global_seed\": meta[\"seed\"],\n",
    "                \"retriever\": meta[\"index_metric\"],\n",
    "                \"dataset_name\": meta[\"dataset\"][\"name\"],\n",
    "                \"model_name\": meta[\"model\"][\"name\"],\n",
    "                \"strategy_name\": meta[\"strategy\"][\"name\"],\n",
    "            }\n",
    "            hparams.append(exp_hparam)\n",
    "            DATA_SEEDS.add(exp_hparam[\"data_seed\"])\n",
    "            MODEL_SEEDS.add(exp_hparam[\"model_seed\"])\n",
    "            INIT_SEEDS.add(exp_hparam[\"initial_seed\"])\n",
    "            STRATEGIES.add(exp_hparam[\"strategy_name\"])\n",
    "\n",
    "        # read experiment logs\n",
    "        if not (experiment / \"tensorboard_logs.parquet\").exists():\n",
    "            unfinished.append(experiment)\n",
    "\n",
    "hparams_df = pd.DataFrame(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = pd.DataFrame(\n",
    "    product(DATASETS, DATA_SEEDS, MODEL_SEEDS, INIT_SEEDS, STRATEGIES),\n",
    "    columns=[\"dataset_name\", \"data_seed\", \"model_seed\", \"initial_seed\", \"strategy_name\"],\n",
    ")\n",
    "all_experiments.groupby([\"dataset_name\", \"strategy_name\"]).size().unique()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = pd.merge(all_experiments, hparams_df, on=all_experiments.columns.tolist(), how=\"outer\", indicator=True)\n",
    "missing = outer.loc[outer[\"_merge\"] != \"both\", all_experiments.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing[[\"dataset_name\", \"strategy_name\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"amazon-rel\", \"wikitoxic-.01\", \"amazon-agri\", \"agnews-business-.01\"]\n",
    "(\n",
    "    missing.loc[\n",
    "        (missing[\"dataset_name\"].isin(names))\n",
    "        # & (missing[\"strategy_name\"] != \"entropy\")\n",
    "    ].sort_values([\"dataset_name\", \"strategy_name\"])  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard fix\n",
    "\n",
    "Build tensorboard.parquet for unfinished runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../outputs/ablations/\")\n",
    "for d in path.iterdir():\n",
    "    if not d.is_dir():\n",
    "        continue\n",
    "    for p in tqdm(list((d).iterdir()), desc=d.name):\n",
    "        if (p / \"tensorboard_logs.parquet\").exists() or not (p / \"tb_logs\").exists():\n",
    "            continue\n",
    "\n",
    "        tb_logs_path = p / \"tb_logs\"\n",
    "        logs = SummaryReader(tb_logs_path)\n",
    "        logs.scalars.to_parquet(p / \"tensorboard_logs.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
