{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import duckdb as db\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import srsly\n",
    "from duckdb.typing import DOUBLE\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = Path(\"../outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = list(run_path.rglob(\"*hparams.yaml\"))\n",
    "paths = [p for p in run_path.rglob(\"*hparams.yaml\") if any(i in str(p) for i in (\"ablations\", \"main\", \"other_models\"))]\n",
    "\n",
    "hparams = []\n",
    "for p in tqdm(paths):\n",
    "    h: dict = srsly.read_yaml(p)  # type: ignore\n",
    "    h[\"filename\"] = str(p.parents[0])\n",
    "    hparams.append(h)\n",
    "\n",
    "hparams_df = pd.concat([pd.json_normalize(h, sep=\".\") for h in hparams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_df.to_csv(\"../results/hparams.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = [str(p) for p in run_path.rglob(\"*tensorboard_logs.parquet\")]\n",
    "paths = [\n",
    "    str(p)\n",
    "    for p in run_path.rglob(\"*tensorboard_logs.parquet\")\n",
    "    if any(i in str(p) for i in (\"ablations\", \"main\", \"other_models\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.sql(\n",
    "    f\"\"\"\n",
    "select\n",
    "    step, \n",
    "    tag, \n",
    "    value, \n",
    "    parse_dirpath(filename) as filename\n",
    "from read_parquet({paths}, filename=True)\n",
    "where contains(tag, 'test/f1_class') or tag == 'timer/query_time'\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x: list[float]) -> float:\n",
    "    return np.trapz(x)\n",
    "\n",
    "\n",
    "# con.remove_function(\"trapz\")\n",
    "db.create_function(\"trapz\", fn, [\"DOUBLE[]\"], DOUBLE)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tbl = db.sql(\n",
    "    \"\"\"\n",
    "-- Collect values into list\n",
    "with ctx as (\n",
    "select\n",
    "    * exclude (value), \n",
    "    list(value) over (partition by filename, tag order by step) as values\n",
    "from tbl\n",
    ")\n",
    "\n",
    "-- Aggregate\n",
    "select\n",
    "    * exclude (values),\n",
    "    case\n",
    "        when contains(tag, 'timer/') then list_sum(values) / 60\n",
    "        else trapz(values)\n",
    "    end as value\n",
    "from ctx\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_tbl.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_parquet(\"../results/metrics.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export subpool information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    str(p)\n",
    "    for p in run_path.rglob(\"*subpool_ids.jsonl\")\n",
    "    if any(i in str(p) for i in (\"ablations\", \"main\", \"other_models\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpool_tbl = db.sql(\n",
    "    f\"\"\"\n",
    "select\n",
    "    parse_dirpath(parse_dirpath(filename)) as filename,\n",
    "    labelling_round, \n",
    "    unnest(subpool_ids) as subpool_ids\n",
    "from read_json({paths}, filename=True, columns = {{subpool_ids: 'INT32[]', labelling_round: 'INT32'}})\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"copy subpool_tbl to '../results/subpool_ids.parquet' (format 'parquet', codec 'zstd')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    str(p)\n",
    "    for p in run_path.rglob(\"*labelled_dataset.parquet\")\n",
    "    if any(i in str(p) for i in (\"ablations\", \"main\", \"other_models\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.sql(\n",
    "    f\"\"\"\n",
    "with ctx as (\n",
    "    select\n",
    "        parse_dirpath(parse_dirpath(filename)) as filename,\n",
    "        uid,\n",
    "        labels,\n",
    "        labelling_round\n",
    "    from read_parquet({paths}, filename=True)\n",
    "    where is_labelled == true\n",
    ")\n",
    "select \n",
    "    filename,\n",
    "    labelling_round,\n",
    "    labels,\n",
    "    count(1) as n\n",
    "from ctx\n",
    "group by filename, labelling_round, labels\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tbl = db.sql(\n",
    "    \"\"\"\n",
    "select *, sum(n) over (partition by filename, labels order by labelling_round) as cum_n\n",
    "from tbl\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"copy label_tbl to '../results/labelled_ids.parquet' (format 'parquet', codec 'zstd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
